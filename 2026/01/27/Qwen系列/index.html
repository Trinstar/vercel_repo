<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"/><meta name="theme-color" content="#222"/><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"/><meta name="renderer" content="webkit"/><link rel="icon" type="image/ico" sizes="32x32" href="/assets/my_favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"/><link rel="alternate" href="/rss.xml" title="cxrc" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="cxrc" type="application/atom+xml"><link rel="alternate" type="application/json" title="cxrc" href="http://example.com/feed.json"/><link rel="preconnect" href="https://s4.zstatic.net"/><link rel="preconnect" href="https://at.alicdn.com"/><link rel="preconnect" href="https://images.trinstar.cn"/><link rel="dns-prefetch" href="https://images.trinstar.cn"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="modulepreload" href="/js/siteInit.js"></link><link rel="modulepreload" href="/js/nyx-player-S77Y4TIY.js"></link><link rel="modulepreload" href="/js/copy-tex-DRKZKT5O.js"></link><link rel="modulepreload" href="/js/post-U2IMGFDZ.js"></link><link rel="modulepreload" href="/js/chunk-4RFIAJTC.js"></link><link rel="modulepreload" href="/js/index.esm-7ZLOLPOD.js"></link><link rel="modulepreload" href="/js/chunk-HJSTZ4VX.js"></link><link rel="modulepreload" href="/js/chunk-4LHORPXG.js"></link><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/custom.css"/><link rel="preload" href="https://images.trinstar.cn/202601_20260127200002255.png" as="image" fetchpriority="high"><meta name="keywords" content="LLM"/><meta name="description" content="Trinstar's Blog"/><link rel="canonical" href="http://example.com/2026/01/27/Qwen%E7%B3%BB%E5%88%97/"><link rel="stylesheet" href="/css/post.css?v=0.5.1"><link rel="stylesheet" href="/css/mermaid.css?v=0.5.1"><!-- 临时处理--><link rel="stylesheet" media="none" onload="this.media='all'" href="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.css"><title>Qwen系列</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Qwen系列</h1><div class="meta"><span class="item" title="Created: 2026-01-27 17:17:29"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">Posted on </span><time itemprop="dateCreated datePublished" datetime="2026-01-27T17:17:29+08:00">2026-01-27</time></span><span class="item" title="Symbols count in article "><span class="icon"><i class="ic i-pen"></i></span><span class="text">Symbols count in article </span><span>4.6k</span><span class="text"> words</span></span><span class="item" title="Reading time "><span class="icon"><i class="ic i-clock"></i></span><span class="text">Reading time </span><span>4  mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Trinstar's Blog</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><img src="https://images.trinstar.cn/202601_20260127200002255.png" loading="eager" decoding="async" fetchpriority="high" alt="cxrc"></div></header><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemListElement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">Home</a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" lang="en"><link itemprop="mainEntityOfPage" href="http://example.com/2026/01/27/Qwen%E7%B3%BB%E5%88%97/"/><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/avatar.webp"/><meta itemprop="name" content="Trinstar"/><meta itemprop="description" content=", Trinstar's Blog"/></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="cxrc"/></span><div class="body md" itemprop="articleBody"><h1 id="1-qwen系列模型源码阅读"><a class="anchor" href="#1-qwen系列模型源码阅读">#</a> 1. Qwen 系列模型源码阅读</h1>
<p>Qwen3 系列开源了两个 MoE 模型，其中，235B 和 30B 表示模型总参数量，A22B 和 A3B 表示激活的参数量：</p>
<ul>
<li>Qwen3-235B-A22B</li>
<li>Qwen3-30B-A3B</li>
</ul>
<p>此外，还有六个开源密集模型：Qwen3-32B、Qwen3-14B、Qwen3-8B、Qwen3-4B、Qwen3-1.7B、Qwen3-0.6B 以及多种量化的版本。</p>
<p>源码在<a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers/tree/main/src/transformers/models"> transformers</a> 库下，具体位置在 <code>/src/models</code> ：<br />
<img loading="lazy" src="https://images.trinstar.cn/202601_20260126224642440.png" alt="image.png" /></p>
<h2 id="11-qwen3-moe"><a class="anchor" href="#11-qwen3-moe">#</a> 1.1. Qwen3-moe</h2>
<p>Qwen3-235B-A22B 使用的是 Qwen3-moe，模型结构的源码位于 <a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/qwen3_moe/modeling_qwen3_moe.py">qwen3_moe/modeling_qwen3_moe.py</a>，以下是对其源码的简单分析。</p>
<h3 id="111-位置编码"><a class="anchor" href="#111-位置编码">#</a> 1.1.1. 位置编码</h3>
<p>qwen3 使用的是旋转位置编码（rotary position embedding, RoPE），具体实现：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">rotate_half</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    x1 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    x2 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">2</span> <span class="token punctuation">:</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span>x2<span class="token punctuation">,</span> x1<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">def</span> <span class="token function">apply_rotary_pos_emb</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> cos<span class="token punctuation">,</span> sin<span class="token punctuation">,</span> unsqueeze_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    cos <span class="token operator">=</span> cos<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>unsqueeze_dim<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    sin <span class="token operator">=</span> sin<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>unsqueeze_dim<span class="token punctuation">)</span></pre></td></tr><tr class="marked"><td data-num="9"></td><td><pre>    q_embed <span class="token operator">=</span> <span class="token punctuation">(</span>q <span class="token operator">*</span> cos<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>rotate_half<span class="token punctuation">(</span>q<span class="token punctuation">)</span> <span class="token operator">*</span> sin<span class="token punctuation">)</span></pre></td></tr><tr class="marked"><td data-num="10"></td><td><pre>    k_embed <span class="token operator">=</span> <span class="token punctuation">(</span>k <span class="token operator">*</span> cos<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>rotate_half<span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token operator">*</span> sin<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">return</span> q_embed<span class="token punctuation">,</span> k_embed</pre></td></tr></table></figure><hr />
<h3 id="112-rmsnorm"><a class="anchor" href="#112-rmsnorm">#</a> 1.1.2. RMSNorm</h3>
<p>Qwen3-moe 使用 RMSNorm 的归一化方法。</p>
<hr />
<h3 id="113-分组注意力grouped-attention"><a class="anchor" href="#113-分组注意力grouped-attention">#</a> 1.1.3. 分组注意力 (Grouped Attention)</h3>
<p>Qwen3-moe 使用了分组注意力机制，但是<strong>唯一</strong>的区别是<strong>在计算完 <code>q</code> ， <code>k</code>  之后会经过一个 <code>RMSnorm</code>  层</strong>，具体实现如下：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>self<span class="token punctuation">.</span>q_norm <span class="token operator">=</span> Qwen3MoeRMSNorm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>head_dim<span class="token punctuation">,</span> eps<span class="token operator">=</span>config<span class="token punctuation">.</span>rms_norm_eps<span class="token punctuation">)</span>  <span class="token comment"># unlike olmo, only on the head dim!</span></pre></td></tr><tr><td data-num="2"></td><td><pre>self<span class="token punctuation">.</span>k_norm <span class="token operator">=</span> Qwen3MoeRMSNorm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>head_dim<span class="token punctuation">,</span> eps<span class="token operator">=</span>config<span class="token punctuation">.</span>rms_norm_eps<span class="token punctuation">)</span>  <span class="token comment"># thus post q_norm does not need reshape</span></pre></td></tr><tr><td data-num="3"></td><td><pre>···</pre></td></tr><tr class="marked"><td data-num="4"></td><td><pre>query_states <span class="token operator">=</span> self<span class="token punctuation">.</span>q_norm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>q_proj<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>hidden_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr><tr class="marked"><td data-num="5"></td><td><pre>key_states <span class="token operator">=</span> self<span class="token punctuation">.</span>k_norm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>k_proj<span class="token punctuation">(</span>hidden_states<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>hidden_shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span></pre></td></tr></table></figure><hr />
<h3 id="114-mlp-moe"><a class="anchor" href="#114-mlp-moe">#</a> 1.1.4. MLP &amp; MoE</h3>
<p>MLP 和 MoE 均采用 <a href="/2026/01/26/LLM%E4%B8%AD%E7%9A%84SwiGLU/" title="LLM中的SwiGLU">SwiGLU</a> 实现。在 Qwen3MoeExperts 中，采用了单个张量来存储所有专家的权重，并且为了计算效率，将 gate 和 up 投影层融合为了 gate_up_proj：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Qwen3MoeExperts</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>        <span class="token comment"># ...</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token comment"># 融合了 gate 和 up 投影，维度为 [num_experts, 2 * intermediate_dim, hidden_dim]</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        self<span class="token punctuation">.</span>gate_up_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_experts<span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>intermediate_dim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_dim<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_states<span class="token punctuation">,</span> top_k_index<span class="token punctuation">,</span> top_k_weights<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token comment"># ...</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token comment"># chunk 操作将融合的维度分开</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        gate<span class="token punctuation">,</span> up <span class="token operator">=</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>current_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gate_up_proj<span class="token punctuation">[</span>expert_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        current_hidden_states <span class="token operator">=</span> self<span class="token punctuation">.</span>act_fn<span class="token punctuation">(</span>gate<span class="token punctuation">)</span> <span class="token operator">*</span> up</pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token comment"># ...</span></pre></td></tr></table></figure><div class="note info">
<p><strong>混合层架构 (Hybrid Layer Architecture)</strong><br />
 Qwen3-MoE 模型并不全是 MoE 层，而是采用了混合架构。 具体来说，设置了 <code>mlp_only_layers</code>  的特殊层数仅使用 MLP，同时每隔一定数量（ <code>decoder_sparse_step</code> ）的 layers（例如每 2 层或 4 层）会插入一个 MoE 层。这种设计旨在在保持模型容量的同时，控制计算资源的使用，从而实现更高效的训练和推理。</p>
</div>
<hr />
<h3 id="115-路由机制与负载均衡-router-load-balancing"><a class="anchor" href="#115-路由机制与负载均衡-router-load-balancing">#</a> 1.1.5. 路由机制与负载均衡 (Router &amp; Load Balancing)</h3>
<h4 id="1151-路由机制-router"><a class="anchor" href="#1151-路由机制-router">#</a> 1.1.5.1. 路由机制 (Router)</h4>
<p>路由模块使用一个线性层生成 logits，并没有复杂的门控网络，直接取 Top-K 的专家作为路由目标：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">Qwen3MoeTopKRouter</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> config<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="3"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        self<span class="token punctuation">.</span>num_experts <span class="token operator">=</span> config<span class="token punctuation">.</span>moe_num_experts</pre></td></tr><tr><td data-num="5"></td><td><pre>        self<span class="token punctuation">.</span>top_k <span class="token operator">=</span> config<span class="token punctuation">.</span>moe_top_k</pre></td></tr><tr class="marked"><td data-num="6"></td><td><pre>        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_experts<span class="token punctuation">,</span> config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token comment"># ...</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_states<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token comment"># ...</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        router_logits <span class="token operator">=</span> F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>hidden_states<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        router_logits <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>router_logits<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        <span class="token comment"># (total_tokens, num_experts)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        router_top_value<span class="token punctuation">,</span> router_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>router_logits<span class="token punctuation">,</span> self<span class="token punctuation">.</span>top_k<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token comment"># (total_tokens, top_k)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>        <span class="token comment"># ...</span></pre></td></tr></table></figure><h4 id="1152-负载均衡-load-balancing"><a class="anchor" href="#1152-负载均衡-load-balancing">#</a> 1.1.5.2. 负载均衡 (Load Balancing)</h4>
<p>为了避免 “专家坍缩”（即大部分 token 集中到少数专家），使用了 <a target="_blank" rel="noopener" href="https://huggingface.co/papers/2101.03961">Switch Transformer</a> 的辅助损失函数。公式如下：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>a</mi><mi>u</mi><mi>x</mi></mrow></msub><mo>=</mo><mi>N</mi><mo>⋅</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>f</mi><mi>i</mi></msub><mo>⋅</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">L_{aux} = N \cdot \sum_{i=1}^{N} f_i \cdot P_i
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">ux</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 是专家数量</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个专家的使用频率</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个专家的平均 logits 概率。</li>
</ul>
<p>具体实现如下：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">def</span> <span class="token function">load_balancing_loss_func</span><span class="token punctuation">(</span>gate_logits<span class="token punctuation">,</span> num_experts<span class="token punctuation">,</span> top_k<span class="token punctuation">,</span> attention_mask<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token comment"># ...</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token comment"># 计算实际路由到每个专家的 token 比例</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    tokens_per_expert <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>expert_mask<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token comment"># 计算路由器分配给每个专家的平均概率</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    router_prob_per_expert <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>routing_weights<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token comment"># 辅助损失 = sum (f_i * P_i) * N</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    overall_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>tokens_per_expert <span class="token operator">*</span> router_prob_per_expert<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">return</span> overall_loss <span class="token operator">*</span> num_experts</pre></td></tr></table></figure><div class="note info">
<p><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 解释</strong></p>
<ul>
<li><code>tokens_per_expert</code>  也就是 <strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></strong>，计算的是 topk 之后，实际分配到该专家的 token 数量除以总 token 数量；</li>
<li><code>router_prob_per_expert</code>  也就是 <strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></strong>，是 softmax 之后，<strong>所有 token</strong> 分配给该专家的概率的平均值。</li>
</ul>
<p>这样子设计的原因是如果一个专家被频繁选择（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">f_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 大），但是路由器对它的信心不高（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 小），说明 routing 不稳定。而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>∑</mo><msub><mi>f</mi><mi>i</mi></msub><mo>∗</mo><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">loss = \sum f_i * P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">oss</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 最小是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>=</mo><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mi>K</mi><mi mathvariant="normal">/</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">f_i = P_i = K / N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 的时候，此时负载均衡。</p>
</div>
<hr />
<h3 id="116-共享嵌入层与输出层权重"><a class="anchor" href="#116-共享嵌入层与输出层权重">#</a> 1.1.6. 共享嵌入层与输出层权重</h3>
<p>Qwen3-moe 模型采用了共享嵌入层（embedding）和输出层的权重（lm_head）</p>
<div class="tags"><a href="/tags/LLM/" rel="tag"><i class="ic i-tag"></i>LLM</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">Edited on  </span><time title="Modified: 2026-01-26 22:44:00" itemprop="dateModified" datetime="2026-01-26T22:44:00+08:00">2026-01-26</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img loading="lazy" src="/assets/wechatpay.jpg" alt="Trinstar WeChat Pay"/><p>WeChat Pay</p></div><div><img loading="lazy" src="/assets/alipay.jpg" alt="Trinstar Alipay"/><p>Alipay</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Trinstar<i class="ic i-at"><em>@</em></i>cxrc</li><li class="link"><strong>Post link: </strong><a href="http://example.com/2026/01/27/Qwen%E7%B3%BB%E5%88%97/" title="Qwen系列">http://example.com/2026/01/27/Qwen系列/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2026/01/26/LLM%E4%B8%AD%E7%9A%84SwiGLU/" rel="prev" itemprop="url" data-background-image="https:&#x2F;&#x2F;images.trinstar.cn&#x2F;202601_20260128194142218.png" title="LLM中的SwiGLU"><span class="type">Previous Post</span><h3>LLM中的SwiGLU</h3></a></div><div class="item right"><a href="/2026/01/28/Flash%20Attention/" rel="next" itemprop="url" data-background-image="https:&#x2F;&#x2F;images.trinstar.cn&#x2F;202601_20260128194654956.png" title="Flash Attention"><span class="type">Next Post</span><h3>Flash Attention</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-qwen%E7%B3%BB%E5%88%97%E6%A8%A1%E5%9E%8B%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB"><span class="toc-text"> 1. Qwen 系列模型源码阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-qwen3-moe"><span class="toc-text"> 1.1. Qwen3-moe</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#111-%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-text"> 1.1.1. 位置编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#112-rmsnorm"><span class="toc-text"> 1.1.2. RMSNorm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#113-%E5%88%86%E7%BB%84%E6%B3%A8%E6%84%8F%E5%8A%9Bgrouped-attention"><span class="toc-text"> 1.1.3. 分组注意力 (Grouped Attention)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#114-mlp-moe"><span class="toc-text"> 1.1.4. MLP &amp; MoE</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#115-%E8%B7%AF%E7%94%B1%E6%9C%BA%E5%88%B6%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-router-load-balancing"><span class="toc-text"> 1.1.5. 路由机制与负载均衡 (Router &amp; Load Balancing)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1151-%E8%B7%AF%E7%94%B1%E6%9C%BA%E5%88%B6-router"><span class="toc-text"> 1.1.5.1. 路由机制 (Router)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1152-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-load-balancing"><span class="toc-text"> 1.1.5.2. 负载均衡 (Load Balancing)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#116-%E5%85%B1%E4%BA%AB%E5%B5%8C%E5%85%A5%E5%B1%82%E4%B8%8E%E8%BE%93%E5%87%BA%E5%B1%82%E6%9D%83%E9%87%8D"><span class="toc-text"> 1.1.6. 共享嵌入层与输出层权重</span></a></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="Related"></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="Trinstar" src="/assets/avatar.webp"/><p class="name" itemprop="name">Trinstar</p><div class="description" itemprop="description">Trinstar's Blog</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">6</span><span class="name">posts</span></a></div><div class="item tags"><a href="/tags/"><span class="count">4</span><span class="name">tags</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/Trinstar" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;Trinstar"><i class="ic i-github"></i></a><a href="/tannyecho@gmail.com" class="item email" title="tannyecho@gmail.com"><i class="ic i-envelope"></i></a><a target="_blank" rel="noopener" href="https://space.bilibili.com/179952417" class="item bilibili" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;179952417"><i class="ic i-bilibili"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-user"></i>About</a><ul class="submenu"><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>About This Site</a></li><li class="item"><a href="/admiration/" rel="section"><i class="ic i-coffee"></i>Appreciation</a></li></ul></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-feather"></i>Posts</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>Friends</a></li></div></div></div></div><ul id="quick"><li class="prev pjax"><a href="/2026/01/28/Flash%20Attention/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2026/01/26/LLM%E4%B8%AD%E7%9A%84SwiGLU/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div><div id="player"></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/28/test/">Untitled</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2025/08/16/Auto%20Send%20IP%20Bot/">Auto Send IP Bot</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/26/LLM%E4%B8%AD%E7%9A%84SwiGLU/">LLM中的SwiGLU</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2025/08/02/%E9%9D%92%E9%BE%994.0%E9%94%AE%E7%9B%98%20%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/">青龙4.0键盘 使用说明</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/28/Flash%20Attention/">Flash Attention</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/27/Qwen%E7%B3%BB%E5%88%97/">Qwen系列</a></span></li></ul></div><div class="rpost pjax"><h2>Recent Comments</h2></div></div><div class="status"><div class="copyright">&copy; 2022 -<span itemprop="copyrightYear">2026</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">Trinstar @ Trinstar's Blog</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="Symbols count total ">16k  words</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="Reading time total ">14  mins.</span></div><div class="powered-by">Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
    path: `2026/01/27/Qwen系列/`,
    favicon: {
        show: `(●´3｀●) Here we go again.`,
        hide: `(´Д｀) It's a disaster!`
    },
    search: {
        placeholder: "Search for Posts",
        empty: "We didn't find any results for the search: ${query}",
        stats: "${hits} results found in ${time} ms"
    },
    nocopy: "false",
    copyright: `Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.`,
    copy_tex: false,
    katex: false,
    mermaid: false,
    audio: undefined,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">Article Timeliness Alert</span><br>This is an article published {{publish}} days ago and last updated {{updated}} days ago. Some information may have changed, so please be careful to screen it.</p></div>`,
    quiz: {
        choice: `Multiple Choice`,
        multiple: `Multiple Answer`,
        true_false: `True/False`,
        essay: `Questions`,
        gap_fill: `Gap Filling`,
        mistake: `Wrong Answer`
    }
};
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=true;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "true");</script><script src="/js/siteInit.js?v=0.5.1" type="module" fetchpriority="high" defer></script></body></html>
<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"/><meta name="theme-color" content="#222"/><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"/><meta name="renderer" content="webkit"/><link rel="icon" type="image/ico" sizes="32x32" href="/assets/my_favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"/><link rel="alternate" href="/rss.xml" title="cxrc" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="cxrc" type="application/atom+xml"><link rel="alternate" type="application/json" title="cxrc" href="http://example.com/feed.json"/><link rel="preconnect" href="https://s4.zstatic.net"/><link rel="preconnect" href="https://at.alicdn.com"/><link rel="preconnect" href="https://images.trinstar.cn"/><link rel="dns-prefetch" href="https://images.trinstar.cn"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="modulepreload" href="/js/siteInit.js"></link><link rel="modulepreload" href="/js/nyx-player-S77Y4TIY.js"></link><link rel="modulepreload" href="/js/copy-tex-DRKZKT5O.js"></link><link rel="modulepreload" href="/js/post-74DYY3SD.js"></link><link rel="modulepreload" href="/js/chunk-SIBYEE2E.js"></link><link rel="modulepreload" href="/js/index.esm-7ZLOLPOD.js"></link><link rel="modulepreload" href="/js/chunk-HJSTZ4VX.js"></link><link rel="modulepreload" href="/js/chunk-4LHORPXG.js"></link><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"></link><link rel="stylesheet" href="/css/custom.css"/><link rel="preload" href="https://images.trinstar.cn/202601_20260128192234654.png" as="image" fetchpriority="high"><meta name="keywords" content="LLM"/><meta name="description" content="Trinstar's Blog"/><link rel="canonical" href="http://example.com/2026/01/29/LoRA%20%E5%BE%AE%E8%B0%83/"><link rel="stylesheet" href="/css/post.css?v=0.5.1"><link rel="stylesheet" href="/css/mermaid.css?v=0.5.1"><!-- 临时处理--><link rel="stylesheet" media="none" onload="this.media='all'" href="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.css"><title>LoRA 微调</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">LoRA 微调</h1><div class="meta"><span class="item" title="Created: 2026-01-29 14:30:47"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">Posted on </span><time itemprop="dateCreated datePublished" datetime="2026-01-29T14:30:47+08:00">2026-01-29</time></span><span class="item" title="Symbols count in article "><span class="icon"><i class="ic i-pen"></i></span><span class="text">Symbols count in article </span><span>6.4k</span><span class="text"> words</span></span><span class="item" title="Reading time "><span class="icon"><i class="ic i-clock"></i></span><span class="text">Reading time </span><span>6  mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Trinstar's Blog</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><img src="https://images.trinstar.cn/202601_20260128192234654.png" loading="eager" decoding="async" fetchpriority="high" alt="cxrc"></div></header><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemListElement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">Home</a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" lang="en"><link itemprop="mainEntityOfPage" href="http://example.com/2026/01/29/LoRA%20%E5%BE%AE%E8%B0%83/"/><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/avatar.webp"/><meta itemprop="name" content="Trinstar"/><meta itemprop="description" content=", Trinstar's Blog"/></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="cxrc"/></span><div class="body md" itemprop="articleBody"><h1 id="1-lora-微调"><a class="anchor" href="#1-lora-微调">#</a> 1. LoRA 微调</h1>
<p>我们使用 Qwen3-1.7B 作为基础模型，模型介绍可以参考 <a href="Qwen%E7%B3%BB%E5%88%97.md">Qwen3 模型介绍</a>。模型权重在 <a target="_blank" rel="noopener" href="https://huggingface.co/Qwen/Qwen3-1.7B">huggingface</a> 可下载。</p>
<p><strong>找寻模型源码：</strong><br />
Qwen3-1.7B 模型使用的是  <code>transformers</code>  库进行加载，可在 <a target="_blank" rel="noopener" href="https://huggingface.co/Qwen/Qwen3-1.7B">huggingface</a> 对应页面查看  <code>config.json</code>  确认：</p>
<figure class="highlight json"><figcaption data-lang="JSON"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token property">"architectures"</span><span class="token operator">:</span> <span class="token punctuation">[</span></pre></td></tr><tr class="marked"><td data-num="3"></td><td><pre>    <span class="token string">"QwenForCausalLM"</span> <span class="token comment">// 表示使用 `QwenForCausalLM` 作为模型架构。</span></pre></td></tr><tr><td data-num="4"></td><td><pre>  <span class="token punctuation">]</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  <span class="token property">"attention_bias"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>  <span class="token property">"attention_dropout"</span><span class="token operator">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="7"></td><td><pre>  <span class="token property">"bos_token_id"</span><span class="token operator">:</span> <span class="token number">151643</span><span class="token punctuation">,</span></pre></td></tr><tr class="marked"><td data-num="8"></td><td><pre>  <span class="token property">"model_type"</span><span class="token operator">:</span> <span class="token string">"qwen3"</span><span class="token punctuation">,</span> <span class="token comment">// 表示在 `transformers` 库下的 `/src/models` 文件夹下的 `qwen3` 模型文件夹中实现了该模型。</span></pre></td></tr><tr><td data-num="9"></td><td><pre>  ...</pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p>下面开始使用 LoRA 微调模型。</p>
<h2 id="11-数据集准备"><a class="anchor" href="#11-数据集准备">#</a> 1.1 数据集准备</h2>
<h3 id="111-jsonl-数据格式"><a class="anchor" href="#111-jsonl-数据格式">#</a> 1.1.1  <code>jsonl</code>  数据格式</h3>
<p>jsonl 是一种轻量级的行式 JSON 格式，<strong>其中每一行都是一个独立的 JSON 对象</strong>，行与行之间互不影响。这种格式非常适合处理大规模对话数据，因为：</p>
<ul>
<li>支持流式读取（无需一次性加载整个文件到内存）；</li>
<li>易于并行处理和分片；</li>
<li>与 Hugging Face  <code>datasets</code>  库、主流训练框架高度兼容。</li>
</ul>
<p>我们的数据采用 OpenAI 风格的聊天格式，每条样本包含一个  <code>messages</code>  字段，其值是一个消息列表（ like  <code>python.list</code> ），交替包含用户（user）和模型（assistant）的对话数据。例如：</p>
<figure class="highlight json"><figcaption data-lang="JSON"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token punctuation">&#123;</span><span class="token property">"messages"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"Hello, who are you?"</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"I am a Qwen model, fine-tuned for your specific task."</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">&#123;</span><span class="token property">"messages"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"What allows you to be fine-tuned so efficiently?"</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"Techniques like LoRA (Low-Rank Adaptation) allow for efficient fine-tuning by freezing most parameters."</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p>使用  <code>datasets</code>  库可以加载此类数据：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset</pre></td></tr><tr><td data-num="2"></td><td><pre>dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span>args<span class="token punctuation">.</span>data_path<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><ul>
<li><code>dataset</code>  是一个  <code>Dataset</code>  对象，包含了所有的数据样本；</li>
<li>加载之后  <code>dataset</code>  中的每个样本（例如 <code>dataset[0]</code> ）都是一个字典（ <code>python.dict</code> ），包含  <code>messages</code>  键，其值是一个消息列表（ <code>python.list</code> ）；</li>
</ul>
<div class="note info">
<p><strong>模型不能直接接受  <code>messages</code>  值列表作为输入</strong>，我们需要将其转换为模型训练所需的文本格式。下面我们详细介绍数据的标准和转化。</p>
</div>
<h3 id="112-数据标准-chat-template"><a class="anchor" href="#112-数据标准-chat-template">#</a> 1.1.2 数据标准 Chat Template</h3>
<p>Chat template 是大语言模型（LLM）中的一个关键组件，它定义了如何将对话转换为模型可以理解的格式化输入。Qwen 采用标准的 ChatML 格式来区分角色。每个消息块都被包裹在特定的起始和结束 Token 之间，例如：</p>
<figure class="highlight xml"><figcaption data-lang="XML"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_start|</span><span class="token punctuation">></span></span>user <span class="token comment">&lt;!-- 隐藏字符 \n --></span></pre></td></tr><tr><td data-num="2"></td><td><pre>Hello, who are you?<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_end|</span><span class="token punctuation">></span></span> <span class="token comment">&lt;!-- 隐藏字符 \n --></span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_start|</span><span class="token punctuation">></span></span>assistant</pre></td></tr><tr><td data-num="4"></td><td><pre>I am a Qwen model, fine-tuned for your specific task.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_end|</span><span class="token punctuation">></span></span></pre></td></tr></table></figure><ul>
<li><code>&lt;|im_start|&gt;&#123;role&#125;\n</code>  和  <code>&lt;|im_end|&gt;\n</code> ：标记消息的开始和结束</li>
<li><code>&#123;role&#125;</code> ：消息的角色（ <code>user</code> 、 <code>assistant</code> 、 <code>system</code> 、 <code>tool</code> ）</li>
<li><code>\n&lt;think&gt;\n</code> ， <code>\n&lt;/think&gt;\n\n</code> ：思考过程</li>
<li><code>&lt;tool_call&gt;\n</code> ， <code>\n&lt;/tool_call&gt;</code> ：工具调用信息。如果  <code>assistant</code>  先说了  <code>content</code>  再调用工具，那么  <code>content</code>  和  <code>&lt;tool_call&gt;</code>  之间会有一个单换行。如果有多个工具连续调用，工具与工具之间也会有一个单换行。结尾  <code>&lt;/tool_call&gt;</code>  之后紧跟  <code>&lt;|im_end|&gt;\n</code> ，没有多余空行。</li>
<li><code>&lt;tool_response&gt;</code> ， <code>&lt;/tool_response&gt;</code> ：工具响应信息。会被包裹在  <code>user</code>  中，如果有多个工具响应，工具响应与工具响应之间会有一个单换行。结尾  <code>&lt;/tool_response&gt;</code>  之后紧跟  <code>&lt;|im_end|&gt;\n</code> ，没有多余空行。</li>
</ul>
<p>模板整体的一个演示例子如下：</p>
<figure class="highlight xml"><figcaption data-lang="XML"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_start|</span><span class="token punctuation">></span></span>system</pre></td></tr><tr><td data-num="2"></td><td><pre># Tools</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>You may call one or more functions to assist with the user query.</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>You are provided with function signatures within <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tools</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tools</span><span class="token punctuation">></span></span> XML tags:</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tools</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="8"></td><td><pre>&#123;"name": "get_weather", "description": "Get the current weather in a given location", "parameters": &#123;"type": "object", "properties": &#123;"city": &#123;"type": "string", "description": "The city and state, e.g. San Francisco, CA"&#125;&#125;, "required": ["city"]&#125;&#125;</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tools</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>For each function call, return a json object with function name and arguments within <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tool_call</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tool_call</span><span class="token punctuation">></span></span> XML tags:</pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tool_call</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="13"></td><td><pre>&#123;"name": <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>function-name</span><span class="token punctuation">></span></span>, "arguments": <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>args-json-object</span><span class="token punctuation">></span></span>&#125;</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tool_call</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_end|</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_start|</span><span class="token punctuation">></span></span>user</pre></td></tr><tr><td data-num="16"></td><td><pre>Could you check the weather in Beijing for me?<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_end|</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_start|</span><span class="token punctuation">></span></span>assistant</pre></td></tr><tr><td data-num="18"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>think</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="19"></td><td><pre>The user wants to know the weather in Beijing. I should call the get_weather tool.</pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>think</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tool_call</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="23"></td><td><pre>&#123;"name": "get_weather", "arguments": &#123;"city": "Beijing"&#125;&#125;</pre></td></tr><tr><td data-num="24"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tool_call</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_end|</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="25"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_start|</span><span class="token punctuation">></span></span>user</pre></td></tr><tr><td data-num="26"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>tool_response</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="27"></td><td><pre>&#123;"temperature": "15°C", "condition": "Sunny"&#125;</pre></td></tr><tr><td data-num="28"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>tool_response</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_end|</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="29"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_start|</span><span class="token punctuation">></span></span>assistant</pre></td></tr><tr><td data-num="30"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>think</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="31"></td><td><pre>The tool returned the specific weather data. I can now provide the final answer to the user.</pre></td></tr><tr><td data-num="32"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>think</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>The current weather in Beijing is sunny with a temperature of 15°C.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>|im_end|</span><span class="token punctuation">></span></span></pre></td></tr></table></figure><p>Chat Template 是模型理解对话上下文和角色的关键。因此我们可以通过调控 Chat Template 来影响模型的行为，这是十分强大的调控手段。比如我们可以通过调控 <code>\n&lt;think&gt;\n</code>  和 <code>\n&lt;/think&gt;\n\n</code>  来选择模型是否 &quot;thinking&quot; 的模式：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>apply_chat_template<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    messages<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    tokenize <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    add_generation_prompt<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr class="marked"><td data-num="5"></td><td><pre>    enable_thinking<span class="token operator">=</span><span class="token boolean">True</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment"># enable_thinking=False</span></pre></td></tr><tr><td data-num="9"></td><td><pre>text <span class="token operator">=</span> <span class="token string">"&lt;|im_start|>user\n42+28等于多少?&lt;|im_end|>\n&lt;|im_start|>assistant\n&lt;think>\n\n&lt;/think>\n\n"</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment"># enable_thinking=True</span></pre></td></tr><tr><td data-num="12"></td><td><pre>text <span class="token operator">=</span> <span class="token string">"&lt;|im_start|>user\n42+28等于多少?&lt;|im_end|>\n&lt;|im_start|>assistant\n"</span></pre></td></tr></table></figure><p>上面的情况唯一的区别是， <code>enable_thinking=False</code>  时添加了一个 <code>&lt;think&gt;\n\n&lt;/think&gt;\n</code> ，用来告诉模型已经思考结束。</p>
<h2 id="11-tokenizer-配置与检测"><a class="anchor" href="#11-tokenizer-配置与检测">#</a> 1.1. Tokenizer 配置与检测</h2>
<p>构建分词器：</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>args<span class="token punctuation">.</span>model_name<span class="token punctuation">,</span> use_fast<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>tokenizer<span class="token punctuation">.</span>pad_token <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>eos_token</pre></td></tr></table></figure><ul>
<li><code>use_fast=False</code>  ：在  <code>transformers</code>  中，&quot;Fast&quot; 分词器通常比纯 Python 实现的版本快得多，且支持偏移映射（offset mapping）等高级功能。是使用 Rust 语言实现的，性能更优。</li>
</ul>
<h3 id="111-检查是否支持fast"><a class="anchor" href="#111-检查是否支持fast">#</a> 1.1.1 检查是否支持 Fast</h3>
<ol>
<li>代码检查，加载分词器后，直接访问它的 .is_fast 属性。这是官方提供的标准接口：</li>
</ol>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"Qwen/Qwen3-1.7B"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>is_fast<span class="token punctuation">)</span></pre></td></tr></table></figure><ol start="2">
<li>查看类名，在 Python 交互界面中直接打印 tokenizer 对象，或者查看它的类型。Fast 版本：类名通常包含 Fast 字样，例如 Qwen2TokenizerFast。Slow 版本：类名通常只是 Qwen2Tokenizer。</li>
</ol>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment"># 输出示例：&lt;class 'transformers.models.qwen2.tokenization_qwen2_fast.Qwen2TokenizerFast'></span></pre></td></tr></table></figure><h2 id="12-量化模型"><a class="anchor" href="#12-量化模型">#</a> 1.2. 量化模型</h2>
<p>QLoRA 论文中提出的一种专门为正态分布权重设计的量化方式，比普通的 4-bit 整数量化精度更高，几乎没有精度损失。类型为  <code>nf4</code>  (Normal Float 4)。</p>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>bnb_config <span class="token operator">=</span> BitsAndBytesConfig<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    load_in_4bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    bnb_4bit_quant_type<span class="token operator">=</span><span class="token string">"nf4"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    bnb_4bit_compute_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">)</span></pre></td></tr></table></figure><ul>
<li><code>bnb_4bit_compute_dtype=torch.float16</code> ：权重是用 4 位 存储的，但在计算（矩阵乘法）时，会将权重临时反量化回到 16 位 (FP16) 进行计算，以提高计算精度和稳定性。</li>
</ul>
<h2 id="13-加载模型"><a class="anchor" href="#13-加载模型">#</a> 1.3. 加载模型</h2>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>        args<span class="token punctuation">.</span>model_name<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>        quantization_config<span class="token operator">=</span>bnb_config <span class="token keyword">if</span> args<span class="token punctuation">.</span>use_4bit <span class="token keyword">else</span> <span class="token boolean">None</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token comment"># Enable gradient checkpointing to save memory</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    model<span class="token punctuation">.</span>gradient_checkpointing_enable<span class="token punctuation">(</span><span class="token punctuation">)</span> </pre></td></tr><tr><td data-num="9"></td><td><pre>    </pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment"># Prepare for k-bit training if using quantization</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">if</span> args<span class="token punctuation">.</span>use_4bit<span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        model <span class="token operator">=</span> prepare_model_for_kbit_training<span class="token punctuation">(</span>model<span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="14-lora-模型"><a class="anchor" href="#14-lora-模型">#</a> 1.4. LoRA 模型</h2>
<figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre>peft_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="2"></td><td><pre>        r<span class="token operator">=</span>args<span class="token punctuation">.</span>lora_r<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="3"></td><td><pre>        lora_alpha<span class="token operator">=</span>args<span class="token punctuation">.</span>lora_alpha<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        lora_dropout<span class="token operator">=</span>args<span class="token punctuation">.</span>lora_dropout<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="5"></td><td><pre>        bias<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        task_type<span class="token operator">=</span>TaskType<span class="token punctuation">.</span>CAUSAL_LM<span class="token punctuation">,</span></pre></td></tr><tr class="marked"><td data-num="7"></td><td><pre>        target_modules<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"q_proj"</span><span class="token punctuation">,</span> <span class="token string">"k_proj"</span><span class="token punctuation">,</span> <span class="token string">"v_proj"</span><span class="token punctuation">,</span> <span class="token string">"o_proj"</span><span class="token punctuation">,</span> <span class="token string">"gate_proj"</span><span class="token punctuation">,</span> <span class="token string">"up_proj"</span><span class="token punctuation">,</span> <span class="token string">"down_proj"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> </pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    </pre></td></tr><tr><td data-num="10"></td><td><pre>    model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> peft_config<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p><code>target_modules</code> ：指定了要应用 LoRA 的模块名称列表。这里列出的模块名称对应于 Qwen3 模型中的注意力机制和前馈网络的线性投影层。<strong>需要根据源码确认具体名称。</strong></p>
<div class="tags"><a href="/tags/LLM/" rel="tag"><i class="ic i-tag"></i>LLM</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">Edited on  </span><time title="Modified: 2026-01-29 17:29:00" itemprop="dateModified" datetime="2026-01-29T17:29:00+08:00">2026-01-29</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img loading="lazy" src="/assets/wechatpay.jpg" alt="Trinstar WeChat Pay"/><p>WeChat Pay</p></div><div><img loading="lazy" src="/assets/alipay.jpg" alt="Trinstar Alipay"/><p>Alipay</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>Trinstar<i class="ic i-at"><em>@</em></i>cxrc</li><li class="link"><strong>Post link: </strong><a href="http://example.com/2026/01/29/LoRA%20%E5%BE%AE%E8%B0%83/" title="LoRA 微调">http://example.com/2026/01/29/LoRA 微调/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2026/01/28/Flash%20Attention/" rel="prev" itemprop="url" data-background-image="https:&#x2F;&#x2F;images.trinstar.cn&#x2F;202601_20260128194654956.png" title="Flash Attention"><span class="type">Previous Post</span><h3>Flash Attention</h3></a></div><div class="item right"></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-lora-%E5%BE%AE%E8%B0%83"><span class="toc-text"> 1. LoRA 微调</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87"><span class="toc-text"> 1.1 数据集准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#111-jsonl-%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"><span class="toc-text"> 1.1.1  jsonl  数据格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#112-%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86-chat-template"><span class="toc-text"> 1.1.2 数据标准 Chat Template</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-tokenizer-%E9%85%8D%E7%BD%AE%E4%B8%8E%E6%A3%80%E6%B5%8B"><span class="toc-text"> 1.1. Tokenizer 配置与检测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#111-%E6%A3%80%E6%9F%A5%E6%98%AF%E5%90%A6%E6%94%AF%E6%8C%81fast"><span class="toc-text"> 1.1.1 检查是否支持 Fast</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-%E9%87%8F%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-text"> 1.2. 量化模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B"><span class="toc-text"> 1.3. 加载模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-lora-%E6%A8%A1%E5%9E%8B"><span class="toc-text"> 1.4. LoRA 模型</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="Related"></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="Trinstar" src="/assets/avatar.webp"/><p class="name" itemprop="name">Trinstar</p><div class="description" itemprop="description">Trinstar's Blog</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">6</span><span class="name">posts</span></a></div><div class="item tags"><a href="/tags/"><span class="count">4</span><span class="name">tags</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/Trinstar" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;Trinstar"><i class="ic i-github"></i></a><a href="/tannyecho@gmail.com" class="item email" title="tannyecho@gmail.com"><i class="ic i-envelope"></i></a><a target="_blank" rel="noopener" href="https://space.bilibili.com/179952417" class="item bilibili" title="https:&#x2F;&#x2F;space.bilibili.com&#x2F;179952417"><i class="ic i-bilibili"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-user"></i>About</a><ul class="submenu"><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>About This Site</a></li><li class="item"><a href="/admiration/" rel="section"><i class="ic i-coffee"></i>Appreciation</a></li></ul></li><li class="item dropdown"><a href="#" onclick="return false;"><i class="ic i-feather"></i>Posts</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>Friends</a></li></div></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2026/01/28/Flash%20Attention/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div><div id="player"></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/2025/08/02/%E9%9D%92%E9%BE%994.0%E9%94%AE%E7%9B%98%20%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/">青龙4.0键盘 使用说明</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/27/Qwen%E7%B3%BB%E5%88%97/">Qwen系列</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2025/08/16/Auto%20Send%20IP%20Bot/">Auto Send IP Bot</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/26/LLM%E4%B8%AD%E7%9A%84SwiGLU/">LLM中的SwiGLU</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/28/Flash%20Attention/">Flash Attention</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/2026/01/29/LoRA%20%E5%BE%AE%E8%B0%83/">LoRA 微调</a></span></li></ul></div><div class="rpost pjax"><h2>Recent Comments</h2></div></div><div class="status"><div class="copyright">&copy; 2022 -<span itemprop="copyrightYear">2026</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">Trinstar @ Trinstar's Blog</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="Symbols count total ">22k  words</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="Reading time total ">20  mins.</span></div><div class="powered-by">Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
    path: `2026/01/29/LoRA 微调/`,
    favicon: {
        show: `(●´3｀●) Here we go again.`,
        hide: `(´Д｀) It's a disaster!`
    },
    search: {
        placeholder: "Search for Posts",
        empty: "We didn't find any results for the search: ${query}",
        stats: "${hits} results found in ${time} ms"
    },
    nocopy: "false",
    copyright: `Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.`,
    copy_tex: false,
    katex: false,
    mermaid: false,
    audio: undefined,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">Article Timeliness Alert</span><br>This is an article published {{publish}} days ago and last updated {{updated}} days ago. Some information may have changed, so please be careful to screen it.</p></div>`,
    quiz: {
        choice: `Multiple Choice`,
        multiple: `Multiple Answer`,
        true_false: `True/False`,
        essay: `Questions`,
        gap_fill: `Gap Filling`,
        mistake: `Wrong Answer`
    }
};
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=true;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "true");</script><script src="/js/siteInit.js?v=0.5.1" type="module" fetchpriority="high" defer></script></body></html>